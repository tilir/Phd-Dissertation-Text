\chapter*{Введение}                         % Заголовок
\addcontentsline{toc}{chapter}{Введение}    % Добавляем его в оглавление

\newcounter{XXcnt}
\setcounter{XXcnt}{20}

Параллельные и распределённые вычисления -- сравнительно новая область, бурно развивающаяся с середины \Roman{XXcnt} века\cite{FirstComputers} и продолжающая существенный рост до сих пор. В последнее время этот рост подстёгивается развитием специализированных устройств, таких как видеокарты, специализированные платы для машинного обучения и ускорители для других выделенных задач. Такие устройства часто не предусматривают возможности запуска операционной системы и прямого взаимодействия с пользователем. Вместо этого они полагаются на то, что где-то существует обычный компьютер, играющий роль \textbf{хоста} который подготавливает вычислительные задачи или \textbf{оффлоады} и отправляет их на устройства, которые заточены на решение задач такого рода \cite{nozal2021exploiting}.

Такой подход называется гетерогенными вычислениями \cite{shan2006heterogeneous}, так как роли хоста и устройства или устройств не равны и они не взаимозаменяемы. Поскольку современные видеокарточки это программируемые процессоры, по мощности часто превосходящие управляющую машину, критичным становится вопрос выбора программного интерфейса между хостом и устройствами. Исторически существует много программных интерфейсов (API) разного качества и с разными целями, как открытых так и закрытых, специфичных для конкретного производителя \cite{HeteroSurvey}.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[scale=0.4]{Vladimirov/images/typical-GPU.pdf}
    }
    \caption{Типичное устройство GPU на примере Intel Gen 11}\label{fig:typicalGPU}
\end{figure}

Типичная современная видеокарточка (вариант Intel Gen 11) представлена на рисунке~\cref{fig:typicalGPU}. Можно видеть большое количество параллельных исполнительных устройств, у каждого из которых есть небольшой кеш первого уровня и на всех один общий кеш третьего уровня (второй уровень пропущен конструктивно). Также в каждом подслое (subslice) можно увидеть блок локальной памяти (SLM), порт для общения с глобальной памятью и некоторые фиксированные функции (медиаблок, самплер).

\nomenclature{\(SLM\)}{shared local memory, разделяемая локальная память}
\nomenclature{\(CPU\)}{central processing unit, центральный процессор}
\nomenclature{\(GPU\)}{graphics processing unit, видеокарточка}
\nomenclature{\(NPU\)}{neural processing unit, карта машинного обучения}
\nomenclature{\(API\)}{application programming interface, программный интерфейс приложения}

С развитием оыбчных процессоров (CPU), количество ядер на них увеличивается. Обычно для функций контроля устройств и подготовки вычислительных задач нужно не более одного аппаратного потока. Это приводит к тому, что гетерогенная система может быть построена не только из специализированных устройств но и из свободных от функций хоста ядер хостового процессора. Такой подход называется гибридным программированием \cite{yang2017hybrid}. При таком подходе можно пересылать данные в глобальную видеопамять и инициировать гетерогенные вычисления через один интерфейс (например CUDA), а потоками хостовой машины управлять через другой интерфейс (например OpenMP). Это возможный подход к гибридной системе но конечно гораздо лучше когда вычислительная задача может быть исполнена на самых разных устройствах и все доступные устройства объединены единым интерфейсом.

На такой единый открытый интерфейс претендует, например, SYCL \cite{da2016comparative}. Есть также вариант SYCL с расширениями Intel, который называется DPC++ \cite{reinders2021dpc}. Но использование таких программных интерфейсов предполагает работу с логической моделью памяти. И здесь критически важной становится то, насколько хорошо мы оптимизируем одну и ту же программу для работы с совершенно разными устройствами. Разумеется каждое устройство имеет собственный компилятор. Например для видеоускорителей компании Intel компилятор называется Intel Graphics Compiler и он доступен публично \cite{chandrasekhar2019igc}.

Таким образом тема исследований оптимизаций в компиляторах для гетерогенных программ и в частности для графических ускорителей является актуальной. Первые публикации по этой теме начали появляться в 2000-х годах \cite{yang2010gpgpu} и тема сравнительно хорошо разработана для скалярных программных интерфейсов, например для уже упоминавшегося OpenMP \cite{lee2009openmp}. Тема которая почти не освещена в текущей литературе это работа с векторными системами команд и оптимизации памяти и потока управления для векторных программных интерфейсов. Эта работа во многом мотивирована появлением высокоуровневых векторных программных интерфейсов, таких как DPC++ESIMD и ISPC \cite{pharr2012ispc}. Язык и система программирования ISPC отлично показали себя на задачах трассировки лучей на векторных CPU, таких как процессоры Intel с расширениями AVX. Необходимость переноса этого успеха на гетерогенные и гибридные системы ставит задачу компиляции высокоуровневого векторного представления в векторную систему команд. Эта задача частично решалась графическим компилятором Intel, но как оптимальность так и функциональная корректность решения оставляли простор для исследований, особенно в части работы с памятью. Так например ранние попытки компилировать программы на ISPC для GPU показали внезапно худшую производительность чем на CPU. Эта работа адресует многие из возникших проблем и является результатом более чем трёхлетней работы автора в компании Intel и преподавания в МФТИ.

\textbf{Целью} данной работы является разработка методов и алгоритмов оптимизации работы с памятью в гетерогенных системах.

Для~достижения поставленной цели необходимо было решить следующие \textbf{задачи}:
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Разработать методологию представления высокоуровневых векторных конструкций в векторной системе команд.
  \item Разработать алгоритм разбиения структур данных для улучшения векторизации.
  \item Разработать алгоритм восстановления векторного потока управления.
\end{enumerate}

\textbf{Объектом исследования} является работа с памятью и потоком управления в гетерогенных системах.

\textbf{Предметом исследования} являются оптимизации в компиляторах для гетерогенных систем.

\textbf{Научная новизна:} 
\begin{enumerate}[beginpenalty=10000]
  \item В диссертационной работе был разработан новый метод ступенчатого понижения промежуточного представления до векторных регионов.
  \item Был разработан новый эффективный алгоритм поэлементного разбиения вложенных структур для улучшения векторизации.
  \item Было разработано предикатное представление векторного потока управления в высокоуровневом промежуточном представлении и алгоритм его восстановления на уровне работы с регионами.
\end{enumerate}

\textbf{Практическая значимость} диссертационной работы заключается в разработанном методе ступенчатого понижения промежуточного представления, алгоритме разбиения структур и алгоритме восстановления векторного потока управления.

Все разработанные методы и алгоритмы были использованы в Intel Graphics Compiler. Разработанные методы и алгоритмы позволили получить существенный прирост производительности на целевых приложениях.

Результаты работы также внедрены в кафедральный курс «Обобщённое программирование» кафедры микропроцессорных технологий в интеллектуальных системах управления МФТИ.

\textbf{Методология и методы исследования} основываются на базовых принципах системного анализа, правилах проектирования программного обеспечения, теории алгоритмов и теории графов и оптимизации.

\textbf{Основные положения выносимые на защиту:}
\begin{enumerate}[beginpenalty=10000]
  \item Метод ступенчатого понижения промежуточного представления до векторных регионов. Заключается в добавлении в конвейер оптимизации компилятора для гетерогенной системы шести обязательных и четырёх оптимизационных пассов для работы с памятью и представлением потока управления.
  \item Представления векторного потока управления в высокоуровневом промежуточном представлении 
  \item Алгоритм восстановления векторного потока управления на уровне работы с регионами.
  \item Алгоритм поэлементного разбиения вложенных структур для улучшения векторизации.
\end{enumerate}

\textbf{Достоверность} полученных результатов проверялась с помощью разработанного программного обеспечения путем замеров производительности вычислительных шейдеров на стандартных системах бенчмаркинга.

\textbf{Апробация работы} основные результаты работы докладывались на
\begin{itemize}
  \item семинарах ФРКТ МФТИ, 2020-2022
  \item семинарах и технических форумах в компании Intel, 2020-2021
\end{itemize}

\textbf{Личный вклад} автор заключается в:
\begin{itemize}
  \item разработке выносимых на защиту метода и алгоритмов.
  \item программной реализации ключевых компонент созданного программного обеспечения.
\end{itemize}

\textbf{Публикации}. Основные результаты по теме диссертации изложены в 2 печатных изданиях, изданых в журнале, рекомендованном МФТИ.

\iffalse

% TODO: сделать vla-characteristic и сделать автореферат оттуда или просто копипаст?

\input{common/characteristic} % Характеристика работы по структуре во введении и в автореферате не отличается (ГОСТ Р 7.0.11, пункты 5.3.1 и 9.2.1), потому её загружаем из одного и того же внешнего файла, предварительно задав форму выделения некоторым параметрам

\fi

\textbf{Объем и структура работы.} Диссертация состоит из~введения,
\formbytotal{totalchapter}{глав}{ы}{}{},
заключения и
\formbytotal{totalappendix}{приложен}{ия}{ий}{}.
%% на случай ошибок оставляю исходный кусок на месте, закомментированным
%Полный объём диссертации составляет  \ref*{TotPages}~страницу
%с~\totalfigures{}~рисунками и~\totaltables{}~таблицами. Список литературы
%содержит \total{citenum}~наименований.
%
Полный объём диссертации составляет
\formbytotal{TotPages}{страниц}{у}{ы}{}, включая
\formbytotal{totalcount@figure}{рисун}{ок}{ка}{ков} и
\formbytotal{totalcount@table}{таблиц}{у}{ы}{}.
Список литературы содержит
\formbytotal{citenum}{наименован}{ие}{ия}{ий}.